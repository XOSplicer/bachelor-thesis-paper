% !TEX root = ../master.tex
\chapter{Design and Methodology}
\label{chap:design}
This chapter describes which research method is used to design a solution 
that answers the initial questions posed in the first chapter.
The considerations that contribute to the design of this solution are outlined 
and form the foundation for its implementation in the next chapter.

\section{Employed Methodology}

Preceding to the practical part of this thesis, 
the method to follow along shall be laid out here.
One suitable method is the general concept of \emph{design science research}, also known as \emph{constructive research}, 
since it involves the development and evaluation of artifacts to solve domain specific problems.
It therefore conveys a improved practical relevance in comparison to purely descriptive research methods,
while the outcomes still create scientific knowledge
\autocite[][p.~v]{dresh2015designresearch}.
The conducted research must design an artifact, such as a construct, model or method, that solves a relevant problem in a specific field, which is evaluated regarding its utility, quality and efficacy.
The performed research should be based on rigorous scientific methods and contribute to the current theoretical body of knowledge.
The conducted design process must take into account the practical environment it is executed in and use the available resources.
A conclusion of the project for both technology-oriented as well as management-oriented audiences should be presented in the end
\autocite[][p.~70]{dresh2015designresearch}.

\begin{figure}[hbt]
	\centering
	\includegraphics[width=0.8\textwidth, keepaspectratio]{resources/designscienceresearchoutputs.jpg}
	\caption[Process steps and outputs of design science research]{\label{fig:design:designscience} Process steps and outputs of design science research. Reprinted from \textcite[][p.~83]{dresh2015designresearch}}
\end{figure}

Figure \ref{fig:design:designscience} displays the steps that are found in the process of design science research. 
Those are the steps that guide the execution of this thesis.
The awareness and relevance for the given problem has already been given in section \vref{sec:into:context}.
Looking back to the original research questions (see section \vref{sec:intro:goals}) two focuses have been identified for this thesis:

\begin{itemize}
    \item Which computer vision techniques can be used to detect persons and objects within an elevator car and in front of the lift and estimate their spacial volume?
    \item How can the information acquired by a system that uses such methods constitute to the optimization of algorithms that control the movement plan for elevators?
\end{itemize}


To answer the two questions, the conducted research is therefore twofold.
The first part involves the design and experimental implementation of a system to gather passengers volume data in elevators.
The second part deals with the integration of this information into a scheduling algorithm.
Outlined below are the steps that are taken to
suggest a tentative design for each, develop the artifacts and evaluate them.

For the  design and implementation of a vision system to gather volume data of passengers,
the following steps are performed:

\begin{enumerate}
    \item Find a typical or actual elevator control system architecture and define the positions to integrate the necessary components for an vision system into it.
    \item Define the exact type and structure of the information that the vision system should be able to detect.
    \item Find an algorithmic approach to  passenger detection and volume estimation that is suitable to generate the required data.
    \item Match the approach with an possible hardware setup to perform tests with it.
    \item Test the proposed detection system in an real world experiment that includes  exemplary footage from within an cabin.
    \item Evaluate the results of the test for the functionality and effectiveness of the employed system.
\end{enumerate}

For the integration of the passenger data into an existing scheduling algorithm the following steps are performed:

\begin{enumerate}
    \item Define a suitable elevator configuration that could possibly benefit from the information that the vision system can provide. 
    Find a typical or actual control algorithm that is used for such a configuration.
    \item Adapt the scheduling algorithm to use the additional information.
    \item Compare the two versions of the algorithm in order to determine their effectiveness regarding a suitable metric.
    A simulation is used to perform this comparison.
\end{enumerate}

%\begin{figure}[hbt]
%	\centering
%	\includegraphics[width=1.0\textwidth, keepaspectratio]{resources/Rasvan_constructive_research_diagram}
%	\caption{\label{fig:design:constructiveresearch} Elements of constructive research. Source:
%	\url{https://en.wikipedia.org/wiki/File:Rasvan_constructive_research_diagram.gif}}
%\end{figure}
 
\section{Visual System}
TODO
\subsection{Proposal for Integration into Elevator Control System Architecture}
TODO
for hardware setup
- no additional sensory
- add cv system (computer) and multiple cams inside each cabin
- add cv system (computer) and multiple or one cam outside on each floor (nope, only inside)

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth, keepaspectratio]{systemcomponets_with_visual}
    \caption[Elevator system extended with visual system]{Elevator system extended with visual system. Addition to figure \ref{fig:sota:systemcomponents}}
    \label{fig:design:systeminteration}
\end{figure}

\subsection{Output Data Definition}
TODO
- for each objects weather it is a person or an cargo object
- for each persons a volume description approximated by an inner and outer ellipse (or simple: circle) as the ground area and a height
- for the cargo objects an approximation as a ground area and a height, possible area types: convex hull most outer circumfence projected to the ground OR estimation by surrounding rectangle
- total number of passengers and cargo objects inside and in-front
\subsection{Detection Technique}

TODO

\begin{figure}
    \centering
    \tikzset{
        box/.style = {
            draw, 
            rectangle, 
            rounded corners, 
            minimum height = 2.5em, 
            minimum width = 2.5em, 
            text width=10em, 
            text centered,
            thick
        },
        to/.style = {
            ->,
            >=stealth',
            shorten >=1pt,
            thick,
            font=\sffamily\footnotesize
        }
    }
    \begin{tikzpicture}[auto, node distance=3em]
        \node (cap) [box] {Video Capture};
        \node (pre) [box, right = of cap] {Preprocessing};
        \node (mask) [box, below = of pre] {Foreground Masking};
        \node (space) [box, below = of mask] {Volume Reconstruction};
        \node (calib) [box, left = of space] {Camera Calibration Data};
        \node (blob) [box, below = of space] {3D Blob Detection};
        \node (meas) [box, below = of blob] {Blob Measurement};
        \node (class) [box, below = of meas] {Blob Classification};
        \draw [to] (cap) -- (pre);
        \draw [to] (pre) -- (mask);
        \draw [to] (mask) -- (space);
        \draw [to] (space) -- (blob);
        \draw [to] (calib) -- (space);
        \draw [to] (blob) -- (meas);
        \draw [to] (meas) -- (class);
    \end{tikzpicture}
    \caption{Volume detection technique}
    \label{fig:design:volumedetection}
\end{figure}

\subsubsection{Video Capture}

TODO cameras, multiple as defined above, live stream via cable

\subsubsection{Preprocessing}
As the first active step, the images of all the cameras 
are read into the memory of the system as \ac{2D} color images 
with native resolution of the cameras.
In order to decrease the computation power needed for the next steps, 
it is possible to \emph{scale them down} to a smaller size.
Furthermore, the camera images typically contain noise, 
which can be countered by applying a \emph{Gaussian blur} filter so it.
The convolution kernel $ G $ shown in figure \ref{fig:sota:kernels} is a candidate,
but also Gaussian kernels of dimension $ 5 \times 5 $ can be used.

\subsubsection{Foreground Masking}
To find out where passengers and objects are visible in each frame from each camera the next step is to find a foreground mask for each of the images.
Since the cameras are static and do not change their position or angle in the cabin,
each camera always films the same section of the elevator.
The perceived background therefor is static except for changes in lighting.
Those can occur when the cabin doors are opened or passengers block the lamps in the cabin.
In contrast to the background, the passengers in the cabin move over time.
The static background with moving passengers allows the method of \emph{background subtraction} to be used.
Either static or dynamic techniques can be used, 
but the dynamic approach of the \ac{MOG} is favourable, 
since it can react to changes in lightning.

The resulting foreground masks might be noisy and can have pixel-sized artifacts.
These originate from noise present in the processed image and small changes between two frames in locations, where actually no passenger is present. 
To remove his noise in the binary foreground mask, the morphological \emph{OPEN} operation is used. 
It is a sequential application of the \emph{ERRODE} and \emph{DILATE}, which firsts removes all edge pixels and then extends the remaining edges again.
This way, single active pixels are deleted, while other structures are preserved.
After this, the \emph{DILATE} operation is applied again to close potential holes in the masks.

\subsubsection{Camera Calibration}
TODO
consider translation, rotation and internal matrix, aswell as distortion

\subsubsection{Volume Reconstruction}
TODO
perform simple volume intersection
therefore project every voxel (chosen low 3d resolution)
into the viewport of the cameras and check, if it is contained in the foregroundmask of all of them,

TODO low resolution to choose

\subsubsection{3D Blob Detection}

The volume intersection in the previous step yielded a \ac{3D} binary image \\
$ F_{vol} \in \{0, 1\}^{X \times Y \times Z}$, where voxels marked with $ 1 $ indicate the presence of an object or passenger at the position of the volume element.
Where ever a passenger or object takes up space in the \ac{3D} image, a \ac{3D} \emph{binary blob} is present, which is a collection of spacial coherent voxels that are positively labeled.
In order to find distinct entities in that image, the \emph{connected component labeling} method can be used.
Initially introduced for \ac{2D} images, it is possible to extend 
the common label-propagation and label-equivalence algorithms to work on a binary image of higher dimensions
\autocite[][p.~39]{he2017connected}.
Since $ X, Y, Z $ have been chosen to be of low resolution, it appears appropriate to use a label-propagation approach.

In a simplified version of this approach, the \ac{3D} image is scanned in a raster, 
and each encountered voxel, that is labeled as 1 in $ F_{vol} $ and has not yet been labeled by the connected component algorithm, it assigned a new unique label.
Furthermore, all neighboring voxels, which are labeled as 1 in $ F_{vol} $, are also labeled with this label.
When a voxel is encountered, which is already labeled, this label is also propagated to its neighbors that are labeled as 1 in $ F_{vol} $. 
The basics of this approach work exactly like in two dimensions, however the definition of neighboring voxels is altered to match three dimensions. 
In general all 26 voxels in the cube around a voxel are considered neighbors.
It is also possible to only consider the 6 voxels, that share a face with the center voxel.

The described algorithm performs a mapping $ \{0, 1\}^{X \times Y \times Z} \rightarrow \mathbb{N}^{X \times Y \times Z} $, where the voxel values of the output represent the unique label of the blob they belong to, or 0 in case that the voxel does not belong to any blob.
Has a complexity of $ \mathcal{O}(X \times Y \times Z) $ and operates without additional memory. 
The algorithm can be improved by performing the label-propagation along the surface of the \ac{3D} blobs.

\subsubsection{Blob Measurement}

The previous step yielded a \ac{3D} image $ F_{blobs} $ consisting of labeled binary blobs.
For each blob, the volume and its length in the X, Y and Z axis are calculated.
The volume is calculated by summing up the volume of the voxels, that make up the blob.
Even when no concrete volume for each voxel is known, this volume is still proportional to the total volume of the containing image $ F_{vol} $.
The length in a particular axis can be found  by calculating the distance of the two most extreme voxels in that axis that belong to the blob.
Figure \ref{fig:design:blobmeasurement} describes the calculations for this measurements for a blob with label $ l $.

\begin{figure}[h!]
\centering{
$$ P_l = \{ (x, y, z) | F_{blobs}(x, y, z) = l\} $$
$$ \Delta{}X_{l} = max(\{ x | (x, y, z) \in P_l \}) - min(\{ x | (x, y, z) \in P_l \}) $$
$$ \Delta{}Y_{l} = max(\{ y | (x, y, z) \in P_l \}) - min(\{ y | (x, y, z) \in P_l \}) $$
$$ \Delta{}Z_{l} = max(\{ z | (x, y, z) \in P_l \}) - min(\{ z | (x, y, z) \in P_l \}) $$
$$ V_{l} = ||P_l|| \times V_{voxel} = \sum\limits_{P_l}^{}V_{voxel} $$
}
\caption{Calculation of 3D blob measurements}
\label{fig:design:blobmeasurement}
\end{figure}

\subsubsection{Blob classification}
With the aid of the previously generated measurements, each blob can be classified to find out whether it reassembles a passenger, a group of passengers, or a large cargo object.
Blobs with a volume smaller than a specific threshold $ T_{min} $ are probably erroneous artifacts and can easily be ignored.
If the volume is human like and the proportions of the blob are higher then wide, it can be classified as a human. 
If the volume is larger than a threshold $ T_{max} $ or if the blob is wider then high, it can be either classified as a large object, or as a group of passengers.

An alternative to this static approach would be to apply machine learning algorithms to find out the classification of a blob.
For this a pre-classified learning data set needs to be available, which might not be feasible.

\subsection{Test Arrangement and Validation Strategy}
To show the general feasibility of the approach described above, 
a real live test is performed.
For this test an exemplary office elevator is used.
Inside it, multiple cameras are mounted at the walls, 
all viewing the center of the cabin.
The cameras do not capture a live stream that is processed but record a video for later processing.
Four cameras are used in the test configuration.
One mounted to the center of each wall of the elevator, in a height of 150~cm.
These cameras are therefore positioned at a right angle towards each other.
An additional camera is mounted over the entry door within the elevator, also facing the center of the elevator.

During the performance of the test there are multiple scenarios
of passengers residing in the cabin:
\begin{itemize}
    \item Empty cabin
    \item Single passenger in multiple positions in the cabin
    \item Multiple passengers in multiple positions in the cabin
    \item Single passenger with a large cargo object in the cabin
    \item Multiple passengers with a large cargo object in the cabin
\end{itemize}
TODO

A typical approach to evaluate the performance of an 
quantitative algorithm in computer vision is to compare it against the \emph{ground truth} present in the observed scene.
The ground truth is a description of the scene in the same format which the algorithm produces, however it is generated by inspection of the original scene by a human.
If the description consists of data for which an order exists, this order can be used for evaluation of the capability of the system.
In general however, the data that is compared might be arbitrarily complex and therefore it is not always possible to perform the comparison quantitatively. Rather a human has to decide, how \enquote{good} the produced results are.


\section{Scheduling Algorithm}
TODO
\subsection{Suitable Elevator Configuration}
Since the camera system is suitable to detect passengers as well as cargo objects,
it seems reasonable to apply the passenger information 
to a scheduling algorithm of an elevator system which conveys both of them.
This hold the opportunity to have a bigger impact the performance of the system, 
in contrast to applying it to a passenger-only lift.

Looking back at the categorization of elevators, cargo lifts meet this specification.
Typically an office building has one or multiple cargo lifts depending on its size,
but grouping them is uncommon \autocite[][p.~167]{barney2016handbook}.
A weight capacity of at least 1,600 kg is typical \autocite[][p.~167]{barney2016handbook},
but also capacities of 5,000 kg are possible \autocite[][]{kone2017overview}.
Typical application areas for cargo lifts are hospitals, where patients and beds are moved,
auxiliary lifts in office buildings and multi-story industrial buildings.
The typical control algorithm is collective control or sequential control \autocite[][pp.~238,~244]{barney2016handbook}.
For this comparison the sequential control and collective control will be taken as a baseline.

\subsection{Adaption of Scheduling Algorithm}




TODO

Therefore a new control strategy is proposed here, which will be called \emph{adaptive control} in the following. 
The strategy is a combination of collective control and sequential control.
It follows these simple rules:

\begin{itemize}
    \item When no cargo item is present in the cabin, the elevator is operated in collective mode and picks up and delivers passengers according to the collective control strategy.
    \item When there is a cargo item present in the cabin, deliver it directly to its destination car call, regardless of other car calls and hall calls.
\end{itemize}

TODO
This implies the necessarity to associate the cargo item to its car call. 
This association can be determined from the combination of the video data and car call data.

\subsection{Preparation for Simulation and Validation Strategy}

TODO texts about the three algorithms

Sequential Control:
\begin{enumerate}[noitemsep]
    \item Update the queue of hall calls by appending all active hall calls that are not yet in the queue.
    \item If there is an active car call:
    \begin{enumerate}[noitemsep]
        \item Move to is respective floor.
        \item Open the doors.
        \item Unload the passenger. 
        \item Close the doors. 
        \item Clear the car call.
    \end{enumerate}
    \item Otherwise, if there is an hall call in the queue:
    \begin{enumerate}[noitemsep]
        \item Move to the floor of the first hall call in the queue. 
        \item Open the doors.
        \item Load one passenger into the lift. 
        \item Delete the hall call from the queue.
        \item Update the car call to be the destination floor of the passenger.
    \end{enumerate}
\end{enumerate}

Non-directional Collective Control:
\begin{enumerate}[noitemsep]
    \item Let the car calls be all the destinations of all passengers present in the lift.
    \item Let the hall calls be all the unique floors where passengers wait for the elevator
    \item If the car calls contain the current floor:
    \begin{enumerate}[noitemsep]
        \item Open the doors.
        \item Unload the passengers for this floor.
    \end{enumerate}
    \item Otherwise, if the hall calls contain the current floor:
    \begin{enumerate}[noitemsep]
        \item Open the doors.
        \item Load all passengers in the floor into the lift, which fit in it.
    \end{enumerate}
    \item Otherwise, if there is another car call or hall call in the current direction of travel:
    \begin{enumerate}[noitemsep]
        \item Close the doors.
        \item Move to the closest car call or hall call in the direction of travel.
    \end{enumerate}
    \item Otherwise reverse the current direction of travel.
\end{enumerate}

Adaptive strategy:
\begin{enumerate}[noitemsep]
    \item If there is a cargo object in the elevator:
    \begin{enumerate}[noitemsep]
        \item Close the doors.
        \item Move to its destination floor.
        \item Open the doors.
        \item Unload the cargo object and other passengers with this destination.
        \item Reset the current travel direction.
    \end{enumerate}
    \item Otherwise, follow the collective control strategy.
\end{enumerate}


TODO simulation configuration:
\autocite[][p.~347]{barney2016handbook}


\begin{table}[]
\centering
\begin{tabular}{lrl}
\textbf{Description} \hspace{4cm}   & \textbf{Value}   & \textbf{Unit}   \\
\hline
\multicolumn{3}{l}{\textbf{Building data}} \\
Number of floors & 8 &        \\
Interfloor distances & 3.5 & $m$\\
%& & \\
\hline
\multicolumn{3}{l}{\textbf{Lift data}}     \\
Number of lifts & 1 & \\
Rated weight load & 5000 & $kg$\\
Rated passenger capacity & 65 & \\
Rated Speed & 1.6 & $ms^{-1}$ \\
Door opening time & 1.5 & $s$\\
Door closing time & 1.5 & $s$\\
Flight time single floor & 8 & $s$\\
%& & \\
\hline
\multicolumn{3}{l}{\textbf{Passenger Data}}\\
Arrival rates for floors & $ (f, t) \rightarrow \frac{7}{300} $ & $ \mathbb{N} \times s \rightarrow s^{-1}$\\
Weight and volume distribution & see table \ref{tab:design:trafficitemprototypes} & $kg \times m \times m \times m \rightarrow \mathbb{R}$\\
%Volume distribution & see below  & $m \times m \times m \rightarrow \mathbb{R} $\\
Transfer time into / out of car & 2 & $s$\\
Floor bias & unbiased & $ \mathbb{N} \times \mathbb{N} \rightarrow \mathbb{R} $ \\
%& & \\
\hline
\multicolumn{3}{l}{\textbf{Cargo Data}}\\
Arrival rates for floors & $ (f, t) \rightarrow \frac{2}{300} $ & $\mathbb{N} \times s \rightarrow s^{-1}$\\
Weight and volume distribution & see table \ref{tab:design:trafficitemprototypes} & $kg \times m \times m \times m \rightarrow \mathbb{R}$\\
%Volume distribution & see below  & $m \times m \times m \rightarrow \mathbb{R} $\\
Transfer time into / out of car & 5 & $s$\\
Floor bias & unbiased & $ \mathbb{N} \times \mathbb{N} \rightarrow \mathbb{R} $ \\
%& & \\
\hline
\multicolumn{3}{l}{\textbf{Simulation Parameters}}\\
Simulation Period & 1 & $h$\\
Time slice & 0.1 & $s$\\
Number of simulations & 1000 & \\
\end{tabular}
\caption{\label{tab:design:simulationconfig} General configuration for the comparative simulation}
\end{table}

\begingroup
\renewcommand*{\arraystretch}{1.0}
\begin{table}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrr}
\textbf{Type}               & \textbf{Width / cm} & \textbf{Length / cm} & \textbf{Height / cm} & \textbf{Weight / kg} \\
\hline
\multirow{4}{*}{Passenger}  & 50                  & 25                   & 160                  & 60                   \\
                            & 50                  & 25                   & 174                  & 65                   \\
                            & 50                  & 25                   & 180                  & 80                   \\
                            & 70                  & 30                   & 190                  & 110                  \\
\hline
\multirow{5}{*}{Cargo Item} & 250                 & 150                  & 150                  & 1000                 \\
                            & 250                 & 150                  & 150                  & 2000                 \\
                            & 250                 & 150                  & 150                  & 3000                 \\
                            & 250                 & 150                  & 150                  & 4000                 \\
                            & 250                 & 150                  & 150                  & 4900                
\end{tabular}%
}
\caption{\label{tab:design:trafficitemprototypes} Prototypes for traffic items in the simulation}
\end{table}
\endgroup

TODO
The arrival rate is constant over the whole time (should this be adapted for several runs?)
therefore in each simulation step the arrival rate is poisson ditributed

TODO: define cargo ites, passangers etc

data from eg. \url{https://www.kone.de/aufzug-aufzuege.aspx} \url{https://www.kone.de/neubau/aufzug-aufzuege/lastenaufzug-bettenaufzug-transys/}
and also \autocite[][p.~349]{barney2016handbook}

which data to use: \autocite[][p.~347]{barney2016handbook}


To evaluate the simulations, several measurements are taken to compare the scheduling algorithms.
For the each of the measures the minimum, maximum, average and standard deviation $ \sigma{} $ values are calculated over all the simulation runs of each scheduling algorithm.  
The following measurements shall be taken:
\begin{samepage}
\begin{itemize}
    \item Total passenger in the simulation
    \item Total cargo objects in the simulation
    \item Stops of the lift
    \item Delivered to their destination
    \item Cargo items delivered to their destination
    \item Waiting time
    \item Ride time
    %\item Maximum, minimum and average total journey time
\end{itemize}
\end{samepage}
 

%\section{Requirements}
%TODO
%\autocite[][]{xang2016trafficlist} has done tehe same and patentet it :(
%\section{Conduction of Method}
%TODO the method determines which steps to take
%TODO, choose possible approach from sota
%\section{Proposed Solution}
%TODO next two are included?
%\section{Architectural Plan}
%TODO necessary? yes
%\section{Algorithmic Approach}
%TODO necessary? yes
%\section{Validation Strategy}
%TODO
